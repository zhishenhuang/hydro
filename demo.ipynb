{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa909aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os,sys\n",
    "import random\n",
    "from skimage.transform import resize\n",
    "import models\n",
    "sys.path.insert(0,'/home/huangz78/hydro/unet3d/')\n",
    "import torch.fft as F\n",
    "from models.unet3d_model import UNet3D, ResidualUNet3D \n",
    "from models.dnet import weights_init, Discriminator\n",
    "import utils\n",
    "from utils import *\n",
    "# from train import gan_train,noise_generate\n",
    "from importlib import reload\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693500b",
   "metadata": {},
   "source": [
    "# track adversial training errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorRec_path = '/mnt/DataA/checkpoints/leo/hydro/wgan_train_track_wg_Abel-gaussian_scaling_1_supwegt0.99_supweigtdecay_0.97_masswegt_10_d_1_g_1_gradpen_10.npz'\n",
    "errordata = np.load(errorRec_path)\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "print(errordata.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2400b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(errordata['nrmse_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f38175",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualization(errordata,errordata.files,log=False,figsize=(10,35))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f976d",
   "metadata": {},
   "source": [
    "# running tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = 999\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "datapath = '/mnt/DataB/hydro_simulations/data/'\n",
    "\n",
    "ncfiles = list([])\n",
    "for file in os.listdir(datapath):\n",
    "    if file.endswith(\".nc\"):\n",
    "        ncfiles.append(file)\n",
    "traintotal = 1000\n",
    "valtotal   = 100\n",
    "testtotal  = 100\n",
    "print('Total amount of available files:', len(ncfiles))\n",
    "print('Train file amount: {}'.format(traintotal))\n",
    "print('Val   file amount: {}'.format(valtotal))\n",
    "print('Test  file amount: {}'.format(testtotal))\n",
    "\n",
    "trainfiles = random.sample(set(ncfiles),k=traintotal)\n",
    "ncfiles = set(ncfiles) - set(trainfiles)\n",
    "valfiles  = random.sample(ncfiles,k=valtotal)\n",
    "ncfiles = set(ncfiles) - set(valfiles)\n",
    "testfiles = random.sample(ncfiles,k=testtotal)\n",
    "# np.savez('/mnt/DataA/checkpoints/leo/hydro/' +f'filesUsed.npz',\\\n",
    "#                  trainfiles=trainfiles,valfiles=valfiles,testfiles=testfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dae51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### running a single test\n",
    "noise_mode = 'Abel-gaussian'\n",
    "scaling    = 2\n",
    "supwgt     = .97\n",
    "batchsize  = 3\n",
    "\n",
    "maxIter    = 1e3\n",
    "postprocess = False\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "massdiff, nrmse, nl1err = test_(gnet,testfiles,batchsize=batchsize,noise_mode=noise_mode,scaling=scaling,\\\n",
    "      device=device,postprocess=postprocess,maxIter=maxIter)\n",
    "# dir_rec = f'/home/leo/hydro/hist_{noise_mode}_{scaling}_supwgt{supwgt}_post_{postprocess}.npz'\n",
    "# np.savez(dir_rec,massdiff=massdiff,nrmse=nrmse,nl1err=nl1err)\n",
    "print(f'test result saved for noise mode {noise_mode}, scaling {scaling}, supwgt {supwgt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### running multiple tests\n",
    "noise_mode   = 'Abel-gaussian'\n",
    "# noise_mode   = 'Abel-gaussian-double'\n",
    "# scaling_grid = 10**np.array([-4, -3, -2, -1, 0.5, 0.66, 0.82, 1, 1.16])\n",
    "scaling_grid = 10**np.array([ -1.])\n",
    "supwgt       = .97\n",
    "batchsize    = 5\n",
    "\n",
    "maxIter      = 1e3\n",
    "postprocess  = False\n",
    "device       = torch.device('cuda:0')\n",
    "# device       = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12311c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a G net\n",
    "gnet = ResidualUNet3D(1,1,num_levels=4,is_segmentation=False,final_sigmoid=False)\n",
    "gpath = f'/mnt/DataA/checkpoints/leo/hydro/netG_sup_{noise_mode}_scaling_1_masswegt_10_epoch9_.pt'\n",
    "checkpoint = torch.load(gpath)\n",
    "gnet.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "gnet.eval()\n",
    "print(f' G net is successfully loaded from {gpath}! ')\n",
    "gnet_params_num = gnet.n_params\n",
    "print('total amount of parameters in gnet: ', gnet_params_num)\n",
    "\n",
    "massdiff_sup_dict = {}\n",
    "nrmse_sup_dict    = {}\n",
    "nl1err_sup_dict   = {}\n",
    "for scaling in scaling_grid:\n",
    "    massdiff, nrmse, nl1err = test_(gnet,testfiles,batchsize=batchsize,noise_mode=noise_mode,scaling=scaling,\\\n",
    "      device=device,postprocess=postprocess,maxIter=maxIter,weight_datafid=5)\n",
    "    massdiff_sup_dict[str(scaling)] = massdiff\n",
    "    nrmse_sup_dict[str(scaling)]    = nrmse\n",
    "    nl1err_sup_dict[str(scaling)]   = nl1err\n",
    "# dir_rec = f'/home/leo/hydro/hist_{noise_mode}_{scaling}_supwgt{supwgt}_post_{postprocess}.npz'\n",
    "# np.savez(dir_rec,massdiff=massdiff,nrmse=nrmse,nl1err=nl1err)\n",
    "    print(f'test result saved for noise mode {noise_mode}, scaling {scaling}, supwgt 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc5f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load a G net\n",
    "gnet = ResidualUNet3D(1,1,num_levels=4,is_segmentation=False,final_sigmoid=False)\n",
    "gpath = f'/mnt/DataA/checkpoints/leo/hydro/netG_wg_{noise_mode}_scaling_1_supwegt0.99_supweigtdecay_0.97_masswegt_10_d_1_g_1_gradpen_10_epoch9_.pt'\n",
    "# gpath = f'/mnt/DataA/checkpoints/leo/hydro/netG_wg_{noise_mode}_scaling_1_supwegt0.9603_supweigtdecay_0.97_masswegt_10_d_1_g_1_gradpen_10_epoch9_.pt'\n",
    "checkpoint = torch.load(gpath)\n",
    "gnet.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "gnet.eval()\n",
    "print(f' G net is successfully loaded from {gpath}! ')\n",
    "gnet_params_num = gnet.n_params\n",
    "print('total amount of parameters in gnet: ', gnet_params_num)\n",
    "\n",
    "### running multiple tests\n",
    "massdiff_wgan_dict = {}\n",
    "nrmse_wgan_dict    = {}\n",
    "nl1err_wgan_dict   = {}\n",
    "for scaling in scaling_grid:\n",
    "    massdiff, nrmse, nl1err = test_(gnet,testfiles,batchsize=batchsize,noise_mode=noise_mode,scaling=scaling,\\\n",
    "      device=device,postprocess=postprocess,maxIter=maxIter,weight_datafid=5)\n",
    "    massdiff_wgan_dict[str(scaling)] = massdiff\n",
    "    nrmse_wgan_dict[str(scaling)]    = nrmse\n",
    "    nl1err_wgan_dict[str(scaling)]   = nl1err\n",
    "# dir_rec = f'/home/leo/hydro/hist_{noise_mode}_{scaling}_supwgt{supwgt}_post_{postprocess}.npz'\n",
    "# np.savez(dir_rec,massdiff=massdiff,nrmse=nrmse,nl1err=nl1err)\n",
    "    print(f'test result saved for noise mode {noise_mode}, scaling {scaling}, supwgt {supwgt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd47652",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_wgan = np.zeros(len(scaling_grid))\n",
    "l1err_wgan = np.zeros(len(scaling_grid))\n",
    "massdiff_wgan = np.zeros(len(scaling_grid))\n",
    "\n",
    "nrmse_wgan_std = np.zeros(len(scaling_grid))\n",
    "l1err_wgan_std = np.zeros(len(scaling_grid))\n",
    "massdiff_wgan_std = np.zeros(len(scaling_grid))\n",
    "\n",
    "for ind in range(len(scaling_grid)):\n",
    "    nrmse_wgan[ind] = np.mean(nrmse_wgan_dict[str(scaling_grid[ind])])\n",
    "    l1err_wgan[ind] = np.mean(nl1err_wgan_dict[str(scaling_grid[ind])])\n",
    "    massdiff_wgan[ind] = np.mean(massdiff_wgan_dict[str(scaling_grid[ind])])\n",
    "    \n",
    "    nrmse_wgan_std[ind] = np.std(nrmse_wgan_dict[str(scaling_grid[ind])])\n",
    "    l1err_wgan_std[ind] = np.std(nl1err_wgan_dict[str(scaling_grid[ind])])\n",
    "    massdiff_wgan_std[ind] = np.std(massdiff_wgan_dict[str(scaling_grid[ind])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56eda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_sup = np.zeros(len(scaling_grid))\n",
    "l1err_sup = np.zeros(len(scaling_grid))\n",
    "massdiff_sup = np.zeros(len(scaling_grid))\n",
    "\n",
    "nrmse_sup_std = np.zeros(len(scaling_grid))\n",
    "l1err_sup_std = np.zeros(len(scaling_grid))\n",
    "massdiff_sup_std = np.zeros(len(scaling_grid))\n",
    "\n",
    "for ind in range(len(scaling_grid)):\n",
    "    nrmse_sup[ind] = np.mean(nrmse_sup_dict[str(scaling_grid[ind])])\n",
    "    l1err_sup[ind] = np.mean(nl1err_sup_dict[str(scaling_grid[ind])])\n",
    "    massdiff_sup[ind] = np.mean(massdiff_sup_dict[str(scaling_grid[ind])])\n",
    "    \n",
    "    nrmse_sup_std[ind] = np.std(nrmse_sup_dict[str(scaling_grid[ind])])\n",
    "    l1err_sup_std[ind] = np.std(nl1err_sup_dict[str(scaling_grid[ind])])\n",
    "    massdiff_sup_std[ind] = np.std(massdiff_sup_dict[str(scaling_grid[ind])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5239c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_mode = 'Abel-gaussian'\n",
    "filename = f'/home/leo/hydro/{noise_mode}_errors.pt'\n",
    "data = torch.load(filename)\n",
    "print('noise mode: ',noise_mode)\n",
    "\n",
    "scaling_grid      = data['scaling_grid']\n",
    "nrmse_wgan        = data['nrmse_wgan']\n",
    "nrmse_wgan_std    = data['nrmse_wgan_std']\n",
    "l1err_wgan        = data['l1err_wgan']\n",
    "l1err_wgan_std    = data['l1err_wgan_std']\n",
    "massdiff_wgan     = data['massdiff_wgan']\n",
    "massdiff_wgan_std = data['massdiff_wgan_std']\n",
    "\n",
    "nrmse_sup         = data['nrmse_sup']\n",
    "nrmse_sup_std     = data['nrmse_sup_std']\n",
    "l1err_sup         = data['l1err_sup']\n",
    "l1err_sup_std     = data['l1err_sup_std']\n",
    "massdiff_sup      = data['massdiff_sup']\n",
    "massdiff_sup_std  = data['massdiff_sup_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new figure 9: Generalization\n",
    "from matplotlib.ticker import FormatStrFormatter, NullFormatter\n",
    "label_fontsize=16\n",
    "tickersize = 13\n",
    "markersize = 9\n",
    "capsize = 9\n",
    "\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(2, 3,figsize=(22,12))\n",
    "\n",
    "axs[0,0].errorbar(scaling_grid[4:],nrmse_sup[4:], yerr=nrmse_sup_std[4:] ,fmt = 'o',capsize=capsize,label='sup')\n",
    "axs[0,0].errorbar(scaling_grid[4:],nrmse_wgan[4:],yerr=nrmse_wgan_std[4:],fmt = 'x',markersize=markersize,capsize=capsize,label='WGAN-sup')\n",
    "axs[0,0].set_xlabel(r\"$\\beta_0$\",fontsize=label_fontsize)\n",
    "axs[0,0].set_ylabel(r\"Relative $\\ell_2$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[0,0].set_xscale('log')\n",
    "axs[0,0].set_xticks(scaling_grid[4:])\n",
    "axs[0,0].set_xticklabels(scaling_grid[4:],fontsize=tickersize)\n",
    "axs[0,0].xaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "axs[0,0].xaxis.set_minor_formatter(NullFormatter())\n",
    "axs[0,0].tick_params(axis='y', labelsize=tickersize)\n",
    "axs[0,0].legend(loc='best')\n",
    "\n",
    "axs[0,1].errorbar(scaling_grid[4:],l1err_sup[4:], yerr=l1err_sup_std[4:] ,fmt = 'o',capsize=capsize,label='sup')\n",
    "axs[0,1].errorbar(scaling_grid[4:],l1err_wgan[4:],yerr=l1err_wgan_std[4:],fmt = 'x',markersize=markersize,capsize=capsize,label='WGAN-sup')\n",
    "axs[0,1].set_xlabel(r\"$\\beta_0$\",fontsize=label_fontsize)\n",
    "axs[0,1].set_ylabel(r\"Relative $\\ell_1$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[0,1].set_xscale('log')\n",
    "axs[0,1].set_xticks(scaling_grid[4:])\n",
    "axs[0,1].set_xticklabels(scaling_grid[4:],fontsize=tickersize)\n",
    "axs[0,1].xaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "axs[0,1].xaxis.set_minor_formatter(NullFormatter())\n",
    "axs[0,1].tick_params(axis='x', which='minor', bottom=False)\n",
    "axs[0,1].tick_params(axis='y', labelsize=tickersize)\n",
    "axs[0,1].legend(loc='best')\n",
    "\n",
    "axs[0,2].errorbar(scaling_grid[4:],massdiff_sup[4:], yerr=massdiff_sup_std[4:],fmt = 'o',capsize=capsize,label='sup')\n",
    "axs[0,2].errorbar(scaling_grid[4:],massdiff_wgan[4:],yerr=massdiff_wgan_std[4:],fmt = 'x',markersize=markersize,capsize=capsize,label='WGAN-sup')\n",
    "axs[0,2].set_xlabel(r\"$\\beta_0$\",fontsize=label_fontsize)\n",
    "axs[0,2].set_ylabel(r\"Relative $\\ell_2$ error in Mass\",fontsize=label_fontsize)\n",
    "axs[0,2].set_xscale('log')\n",
    "axs[0,2].set_xticks(scaling_grid[4:])\n",
    "axs[0,2].set_xticklabels(scaling_grid[4:],fontsize=tickersize)\n",
    "axs[0,2].xaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "axs[0,2].xaxis.set_minor_formatter(NullFormatter())\n",
    "axs[0,2].tick_params(axis='y', labelsize=tickersize)\n",
    "axs[0,2].legend(loc='best')\n",
    "\n",
    "axs[1,0].errorbar(scaling_grid[0:4],nrmse_sup[0:4], yerr=nrmse_sup_std[0:4] ,fmt = 'o',capsize=capsize,label='sup')\n",
    "axs[1,0].errorbar(scaling_grid[0:4],nrmse_wgan[0:4],yerr=nrmse_wgan_std[0:4],fmt = 'x',markersize=markersize,capsize=capsize,label='WGAN-sup')\n",
    "axs[1,0].set_xlabel(r\"$\\beta_0$\",fontsize=label_fontsize)\n",
    "axs[1,0].set_ylabel(r\"Relative $\\ell_2$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[1,0].set_xscale('log')\n",
    "axs[1,0].set_yticks([0.10, 0.11,0.12,0.13])\n",
    "axs[1,0].tick_params(axis='x', labelsize=tickersize)\n",
    "axs[1,0].tick_params(axis='y', labelsize=tickersize)\n",
    "axs[1,0].legend(loc='best')\n",
    "\n",
    "axs[1,1].errorbar(scaling_grid[0:4],l1err_sup[0:4], yerr=l1err_sup_std[0:4] ,fmt = 'o',capsize=capsize,label='sup')\n",
    "axs[1,1].errorbar(scaling_grid[0:4],l1err_wgan[0:4],yerr=l1err_wgan_std[0:4],fmt = 'x',markersize=markersize,capsize=capsize,label='WGAN-sup')\n",
    "axs[1,1].set_xlabel(r\"$\\beta_0$\",fontsize=label_fontsize)\n",
    "axs[1,1].set_ylabel(r\"Relative $\\ell_1$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[1,1].set_xscale('log')\n",
    "# plt.yscale('log')\n",
    "axs[1,1].set_yticks([0.095, 0.105,0.115,0.125])\n",
    "axs[1,1].tick_params(axis='x', labelsize=tickersize)\n",
    "axs[1,1].tick_params(axis='y', labelsize=tickersize)\n",
    "axs[1,1].legend(loc='best')\n",
    "\n",
    "axs[1,2].errorbar(scaling_grid[0:4],massdiff_sup[0:4], yerr=massdiff_sup_std[0:4],fmt = 'o',capsize=capsize,label='sup')\n",
    "axs[1,2].errorbar(scaling_grid[0:4],massdiff_wgan[0:4],yerr=massdiff_wgan_std[0:4],fmt = 'x',markersize=markersize,capsize=capsize,label='WGAN-sup')\n",
    "axs[1,2].set_xlabel(r\"$\\beta_0$\",fontsize=label_fontsize)\n",
    "axs[1,2].set_ylabel(r\"Relative $\\ell_2$ error in Mass\",fontsize=label_fontsize)\n",
    "axs[1,2].set_xscale('log')\n",
    "# axs[1,2].set_yticks([0.59,0.61,0.63])\n",
    "axs[1,2].tick_params(axis='x', labelsize=tickersize)\n",
    "axs[1,2].tick_params(axis='y', labelsize=tickersize)\n",
    "axs[1,2].legend(loc='best')\n",
    "\n",
    "# plt.show()\n",
    "plt.draw()\n",
    "dir_fig = f'/home/leo/hydro/figures/{noise_mode}_generalization.eps'\n",
    "plt.savefig(dir_fig,format='eps',dpi=600,transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(nrmse)\n",
    "plt.title(f'l2err mean={nrmse.mean():.4f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c9961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noise_mode = 'Abel-gaussian'\n",
    "scaling = 1\n",
    "massdiff, nrmse, nl1err = \\\n",
    "                    test_baseline(testfiles,noise_mode=noise_mode,scaling=scaling,device=torch.device('cuda:0'),\\\n",
    "                                  weight_datafid=5,weight_masscon=1e2,weight_TVA=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3452240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_rec = f'/home/leo/hydro/hist_{noise_mode}_{scaling}_baseline_lambda0_5.npz'\n",
    "np.savez(dir_rec,massdiff=massdiff,nrmse=nrmse,nl1err=nl1err)\n",
    "print(f'test result saved for noise mode {noise_mode}, scaling {scaling}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nothing(testfiles,\\\n",
    "          batchsize=5,dep=8,img_size=320,\\\n",
    "          noise_mode='Abel-gaussian',\\\n",
    "          normalize_factor=50,\\\n",
    "          volatility=.05,sigma=2,xi=.02,scaling=1,white_noise_ratio=1e-4,device=torch.device('cpu'),\\\n",
    "          resize_option=False):\n",
    "    testfile_num = len(testfiles)\n",
    "    batchsize = min(testfile_num,batchsize)\n",
    "    \n",
    "    Mass_diff = np.zeros(len(testfiles)); nrmse = np.zeros(len(testfiles)); nl1err = np.zeros(len(testfiles))\n",
    "    # evaluate on validation set\n",
    "    fileind = 0\n",
    "    batch_step = 0\n",
    "    while fileind < testfile_num:\n",
    "        print(f'Current iter: [{fileind}/{testfile_num}]')\n",
    "        dyn, noise = load_data_batch(fileind,testfiles,b_size=batchsize,dep=dep,img_size=img_size,\\\n",
    "                                        resize_option=resize_option,\\\n",
    "                                        noise_mode=noise_mode,normalize_factor=normalize_factor,\\\n",
    "                                        volatility=volatility,sigma=sigma,xi=xi,scaling=scaling,\\\n",
    "                                        white_noise_ratio=white_noise_ratio)\n",
    "        real_cpu = dyn.to(device)\n",
    "        noise    = noise.to(device)\n",
    "        noisy_sg = noise + real_cpu\n",
    "        \n",
    "        noisy_sg[real_cpu==0] = 0\n",
    "\n",
    "        truemass = compute_mass(real_cpu,device=device)\n",
    "\n",
    "        mass_fake = compute_mass(noisy_sg,device=device)\n",
    "        mass_real = compute_mass(real_cpu,device=device)\n",
    "        mass_diff = torch.divide(torch.abs(mass_fake - mass_real), mass_real).sum()/dep\n",
    "        for ind in range(batchsize):\n",
    "            Mass_diff[fileind+ind] = mass_diff\n",
    "            nrmse[fileind+ind]     = aver_mse(noisy_sg[ind:ind+1,:,:,:,:],real_cpu[ind:ind+1,:,:,:,:])\n",
    "            nl1err[fileind+ind]    = aver_l1(noisy_sg[ind:ind+1,:,:,:,:],real_cpu[ind:ind+1,:,:,:,:])\n",
    "        del dyn, real_cpu, noise \n",
    "        fileind += batchsize\n",
    "            \n",
    "    return Mass_diff, nrmse, nl1err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0c9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Mass_diff, nrmse, nl1err = test_nothing(testfiles,batchsize=50,scaling=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63170a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data = [Mass_diff]\n",
    "label = ['mass']\n",
    "plt.boxplot(data,notch=True,labels=label)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "data = [nrmse, nl1err]\n",
    "label = ['l2', 'l1']\n",
    "plt.boxplot(data,notch=True,labels=label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mass_diff, nrmse, nl1err = test_nothing(testfiles,batchsize=50,scaling=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.load('hist_Abel-gaussian_1_baseline_lambda0_5_new.npz')\n",
    "Mass_diff = hist['massdiff']\n",
    "nrmse = hist['nrmse']\n",
    "nl1err = hist['nl1err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e016acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(Mass_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data = [Mass_diff]\n",
    "label = ['mass']\n",
    "plt.boxplot(data,notch=True,labels=label)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "data = [nrmse, nl1err]\n",
    "label = ['L2', 'L1']\n",
    "plt.boxplot(data,notch=True,labels=label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'/home/leo/hydro/{noise_mode}_errors.pt'\n",
    "torch.save({'scaling_grid':scaling_grid,\\\n",
    "            'nrmse_wgan':nrmse_wgan,'l1err_wgan':l1err_wgan,'massdiff_wgan':massdiff_wgan,\\\n",
    "            'nrmse_sup':nrmse_sup,'l1err_sup':l1err_sup,'massdiff_sup':massdiff_sup,\\\n",
    "            'nrmse_sup_std':nrmse_sup_std,'l1err_sup_std':l1err_sup_std,'massdiff_sup_std':massdiff_sup_std,\\\n",
    "            'nrmse_wgan_std':nrmse_wgan_std,'l1err_wgan_std':l1err_wgan_std,'massdiff_wgan_std':massdiff_wgan_std},\n",
    "            filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3107e",
   "metadata": {},
   "source": [
    "# check denoised slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d4d9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datapath = '/mnt/DataB/hydro_simulations/data/'\n",
    "ncfiles = list([])\n",
    "for file in os.listdir(datapath):\n",
    "    if file.endswith(\".nc\"):\n",
    "        ncfiles.append(file)\n",
    "print('Total amount of files:', len(ncfiles))\n",
    "img_size = 320\n",
    "dep = 8 # 41\n",
    "time_pts = torch.round(torch.linspace(0,40,dep)).int() \n",
    "fileexp_ind = np.random.randint(len(ncfiles))\n",
    "# fileexp_ind = 5636 # type 1\n",
    "# fileexp_ind = 12273 # type 2\n",
    "# fileexp_ind = np.random.randint(len(ncfiles))\n",
    "print(f'current file index: {fileexp_ind}')\n",
    "print(f'file name is : {ncfiles[fileexp_ind]}')\n",
    "# for fileexp_ind in range(len(ncfiles)):\n",
    "filename = ncfiles[fileexp_ind]\n",
    "sim = xr.open_dataarray(datapath+filename)\n",
    "sim.close()\n",
    "# subgroup = 0\n",
    "dyn   = torch.zeros((1,1,dep,img_size,img_size))    # load one sample, show it\n",
    "noise = torch.zeros((1,1,dep,img_size,img_size))    \n",
    "for t in range(dep):\n",
    "#     dyn[0,0,t,:,:] = torch.tensor( sim.isel(t=t)[:img_size,:img_size].values )\n",
    "    dyn[0,0,t,:,:] = torch.tensor( sim.isel(t=time_pts[t])[:img_size,:img_size].values )\n",
    "#     dyn[0,0,t,:,:] = torch.tensor( sim.isel(t=t+dep*subgroup)[:img_size,:img_size].values )\n",
    "# for t in range(dep):\n",
    "#     dyn[0,0,t,:,:] = resize(sim.isel(t=t)[:img_size,:img_size].values,(256,256),anti_aliasing=True)\n",
    "\n",
    "normalize_factor   = 50\n",
    "dyn = dyn.clamp(max=normalize_factor)\n",
    "dyn[0,0,:,:,:]  = dyn[0,0,:,:,:] / normalize_factor\n",
    "\n",
    "noise = torch.zeros(dyn.shape) # make a noise sample, add it to the ground truth, show it\n",
    "# for t in range(dep): # different noise for each frame when using a 'for' loop\n",
    "#     noise[0,0,t,:,:] = noise_generate(dyn[0,0,t,:,:],mode='linear',scaling=dyn.max().numpy()) \n",
    "#     noise[0,0,t,:,:] = noise_generate(dyn[0,0,t,:,:],mode='const_rand',scaling=dyn.max().numpy()) \n",
    "illustrate(dyn, vmin=0, vmax=1,title='ground truth dynamics',time_pts=time_pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = 'Abel-gaussian'\n",
    "mode = 'Abel-gaussian-double'\n",
    "scaling = 1 # main\n",
    "sigma = 2\n",
    "volatility = .5\n",
    "xi = .02\n",
    "white_noise_ratio=2e-4\n",
    "noise[0,0,:,:,:] = noise_generate(dyn[0,0,:,:,:],mode=mode,\\\n",
    "                                  sigma=sigma,volatility=volatility,xi=xi,scaling=scaling,\\\n",
    "                                  abel_method='basex',white_noise_ratio=white_noise_ratio) \n",
    "noise[dyn==0] = 0\n",
    "print(torch.norm(noise)/torch.norm(dyn))\n",
    "noisy_dyn = dyn + noise\n",
    "\n",
    "vmax_val = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check line profiles\n",
    "rho_clean = torch_complete(dyn)[0,0,-1,:,:]\n",
    "rho_noisy = torch_complete(noisy_dyn)[0,0,-1,:,:]\n",
    "\n",
    "line_index = 0\n",
    "plt_range =  320\n",
    "\n",
    "plt_type = 1\n",
    "\n",
    "nrows=2; ncols=4\n",
    "figsize=(18,9); fontsize=13\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, figsize=figsize)\n",
    "time_pts = [37 , 37.6, 38.1, 38.7, 39.3, 39.9, 40.4, 41]\n",
    "for t in range(dep): \n",
    "    plt.rcParams.update({'font.size': fontsize})\n",
    "    if plt_type == 1: # horizontal line profile\n",
    "        axs[t//ncols][t%ncols].plot(dyn[0,0,t,:plt_range,line_index], 'r', label='ground truth')\n",
    "        axs[t//ncols][t%ncols].plot(noisy_dyn[0,0,t,:plt_range,line_index], 'k', label='noisy data')\n",
    "#         axs[t//ncols][t%ncols].plot(denoised_dyn[0,0,t,:plt_range,line_index], 'g--', linewidth=2, label='denoised data')\n",
    "#         axs[t//ncols][t%ncols].plot(further_denoised_dyn[0,0,t,:plt_range,line_index], '--', color='#00FF00',linewidth=3 ,label='denoised data')\n",
    "    elif plt_type == 2: # vertical line profile\n",
    "        axs[t//ncols][t%ncols].plot(dyn[0,0,t,line_index,:plt_range], 'r', label='ground truth')\n",
    "        axs[t//ncols][t%ncols].plot(noisy_dyn[0,0,t,line_index,:plt_range], 'k', label='noisy data')\n",
    "#         axs[t//ncols][t%ncols].plot(denoised_dyn[0,0,t,line_index,:plt_range], 'g--', linewidth=2, label='denoised data')\n",
    "#         axs[t//ncols][t%ncols].plot(further_denoised_dyn[0,0,t,line_index,:plt_range], '--', color='#00FF00',linewidth=3 ,label='denoised data')\n",
    "    elif plt_type == 3: # diagonal line profile\n",
    "        gt = [dyn[0,0,t,i,i] for i in range(plt_range)]\n",
    "        noisy_sg = [noisy_dyn[0,0,t,i,i] for i in range(plt_range)]\n",
    "#         denoised_sg = [further_denoised_dyn[0,0,t,i,i] for i in range(plt_range)]\n",
    "        axs[t//ncols][t%ncols].plot(gt, 'r', label='ground truth')\n",
    "        axs[t//ncols][t%ncols].plot(noisy_sg, 'k', label='noisy data')\n",
    "#         axs[t//ncols][t%ncols].plot(denoised_sg, 'g--', linewidth=2, label='denoised data')\n",
    "    axs[t//ncols][t%ncols].set_title(f'$t = {time_pts[t]}$')\n",
    "#     axs[t//ncols][t%ncols].legend(loc='best')\n",
    "    \n",
    "plt.title(f'')\n",
    "handles, labels =  axs[1][2].get_legend_handles_labels()\n",
    "fig.legend(handles, labels=labels,loc=\"lower center\",ncol=3,fontsize='large',bbox_to_anchor=[.5, 0])\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3a8a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_pts = np.arange(dyn.shape[2])\n",
    "# illustrate(dyn, vmin=0, vmax=vmax_val,title='ground truth dynamics',time_pts=time_pts)\n",
    "# illustrate(noise.abs(), vmin=0, vmax=vmax_val,title='noise - absolute value',time_pts=time_pts)\n",
    "illustrate(noisy_dyn, vmin=noise.min(), vmax=vmax_val,title='noisy dynamics',time_pts=time_pts)\n",
    "# illustrate(torch.divide(noise.abs(),dyn),vmin=0, vmax=1,title='relative L1 error',time_pts=time_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1 = '/mnt/DataA/checkpoints/leo/hydro/Abel-Gaussian-noise-example1.npz'\n",
    "print(filename)\n",
    "np.savez(file_name1,source_file_name=filename,noise=noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d593306",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name2 = '/mnt/DataA/checkpoints/leo/hydro/Abel-Gaussian-noise-example2.npz'\n",
    "print(filename)\n",
    "np.savez(file_name2,source_file_name=filename,noise=noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a G net\n",
    "gnet = ResidualUNet3D(1,1,num_levels=4,is_segmentation=False,final_sigmoid=False)\n",
    "# gpath = '/mnt/DataA/checkpoints/leo/hydro/netG_wg_Abel-gaussian_epoch_3.pt'\n",
    "# gpath = '/mnt/DataA/checkpoints/leo/hydro/netG_wg_Abel-gaussian_scaling_1.0_supweigtdecay_1.0_epoch_5.pt'\n",
    "gpath = '/mnt/DataA/checkpoints/leo/hydro/netG_wg_Abel-gaussian-double_epoch_3.pt'\n",
    "checkpoint = torch.load(gpath)\n",
    "gnet.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "gnet.eval()\n",
    "print(f' G net is successfully loaded from {gpath}! ')\n",
    "gnet_params_num = gnet.n_params\n",
    "print('total amount of parameters in gnet: ', gnet_params_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ec2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply denoiser, show the outcome\n",
    "noisy_dyn = noise + dyn\n",
    "denoised_dyn = gnet(noisy_dyn).clamp(min=0).detach()\n",
    "denoised_dyn[dyn==0] = 0\n",
    "print('un-denoised L2 err: ', (torch.norm(noisy_dyn - dyn)/torch.norm(dyn)).item())\n",
    "print('denoised    L2 err: ', (torch.norm(denoised_dyn - dyn)/torch.norm(dyn)).item())\n",
    "print('un-denoised L1 err: ', (torch.norm(noisy_dyn - dyn,p=1)/torch.norm(dyn,p=1)).item())\n",
    "print('denoised    L1 err: ', (torch.norm(denoised_dyn - dyn,p=1)/torch.norm(dyn,p=1)).item())\n",
    "vmax = .5\n",
    "# illustrate(dyn, vmin=0,vmax=vmax,title='ground truth dynamics',   time_pts=time_pts)\n",
    "# illustrate(noisy_dyn, vmin=0,vmax=vmax,title='noisy dynamics',   time_pts=time_pts)\n",
    "# illustrate(denoised_dyn,vmin=0,vmax=vmax,title='denoised dynamics',time_pts=time_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4f67f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "truemass = compute_mass(dyn)\n",
    "further_denoised_dyn = postprocessor(denoised_dyn, truemass,\\\n",
    "                                     lr=1e-5,\\\n",
    "                                     weight_datafid=5, weight_masscon=1e2, weight_TVA=1e-4,\\\n",
    "                                     dyn=dyn,\\\n",
    "                                     maxIter=7e3,\\\n",
    "                                     print_every=500) # denoised_dyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaa189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98635979",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_clean = torch_complete(dyn)[0,0,-1,:,:]\n",
    "rho_noisy = torch_complete(noisy_dyn)[0,0,-1,:,:]\n",
    "rho_denoised = torch_complete(further_denoised_dyn)[0,0,-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a23eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6(a) and 7(a): plot for density frames\n",
    "nrows = 1\n",
    "ncols = 3\n",
    "figsize = (24,12)\n",
    "fontsize = 33\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, figsize=figsize)\n",
    "vmin = 0; vmax = .5\n",
    "for t in range(dep): \n",
    "    plt.rcParams.update({'font.size': fontsize})\n",
    "\n",
    "    hd0 = axs[0].imshow(rho_clean,origin='lower',vmin=vmin,vmax=vmax)\n",
    "    divider0 = make_axes_locatable(axs[0])\n",
    "    cax0 = divider0.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar0 = fig.colorbar(hd0,cax=cax0)\n",
    "    cbar0.set_ticks(np.arange(vmin, vmax, (vmax-vmin)/10))\n",
    "    \n",
    "    hd1 = axs[1].imshow(rho_noisy,origin='lower',vmin=vmin,vmax=vmax)\n",
    "    divider1 = make_axes_locatable(axs[1])\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar1 = fig.colorbar(hd1,cax=cax1)\n",
    "    cbar1.set_ticks(np.arange(vmin, vmax, (vmax-vmin)/10))\n",
    "    \n",
    "    hd2 = axs[2].imshow(rho_denoised,origin='lower',vmin=vmin,vmax=vmax)\n",
    "    divider2 = make_axes_locatable(axs[2])\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar2 = fig.colorbar(hd2,cax=cax2)\n",
    "    cbar2.set_ticks(np.arange(vmin, vmax, (vmax-vmin)/10))\n",
    "    \n",
    "    axs[0].set_title('clean density',fontsize=20)\n",
    "    axs[1].set_title('noisy density',fontsize=20)\n",
    "    axs[2].set_title('denoised density',fontsize=20)\n",
    "    \n",
    "plt.show()\n",
    "dir_fig = '/home/leo/hydro/figures/t40_density_cmp_type_1.eps'\n",
    "# dir_fig = '/home/leo/hydro/figures/t40_density_cmp_type_2.eps'\n",
    "plt.savefig(dir_fig,format='eps',dpi=100,transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_clean_full = torch_complete(dyn)\n",
    "img_clean = abel.Transform(rho_clean_full[0,0,-1,:,:].numpy(), method='basex', direction='forward',verbose=False).transform\n",
    "img_clean = exp_negative(img_clean,xi=0.02)\n",
    "\n",
    "rho_noisy_full = torch_complete(noisy_dyn)\n",
    "img_noisy = abel.Transform(rho_noisy_full[0,0,-1,:,:].numpy(), method='basex', direction='forward',verbose=False).transform\n",
    "img_noisy = exp_negative(img_noisy,xi=0.02)\n",
    "\n",
    "rho_denoised_full = torch_complete(denoised_dyn)\n",
    "img_denoised = abel.Transform(rho_denoised_full[0,0,-1,:,:].numpy(), method='basex', direction='forward',verbose=False).transform\n",
    "img_denoised = exp_negative(img_denoised,xi=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ffbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(img_clean)\n",
    "\n",
    "np.max(np.abs(img_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a11f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6(b) and 7(b): plot for Radiographic frames\n",
    "nrows=1\n",
    "ncols=3\n",
    "figsize=(24,12)\n",
    "fontsize=13\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, figsize=figsize)\n",
    "vmin = -6; vmax = 0\n",
    "for t in range(dep): \n",
    "    plt.rcParams.update({'font.size': fontsize})\n",
    "\n",
    "    orig_map=plt.cm.get_cmap('viridis')\n",
    "    # reversing the original colormap using reversed() function\n",
    "    reversed_cmap = orig_map.reversed()\n",
    "    \n",
    "    #     hd0 = axs[0].imshow(np.log(img_clean),origin='lower')\n",
    "    hd0 = axs[0].imshow(np.log(img_clean),origin='lower',vmin=vmin,vmax=vmax,cmap=reversed_cmap)\n",
    "    divider0 = make_axes_locatable(axs[0])\n",
    "    cax0 = divider0.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar0 = fig.colorbar(hd0,cax=cax0)\n",
    "    cbar0.set_ticks(np.arange(vmin, vmax, (vmax-vmin)/6))\n",
    "    \n",
    "    hd1 = axs[1].imshow(np.log(img_noisy),origin='lower',vmin=vmin,vmax=vmax,cmap=reversed_cmap)\n",
    "#     hd1 = axs[1].imshow(np.log(img_noisy),origin='lower')\n",
    "    divider1 = make_axes_locatable(axs[1])\n",
    "    cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar1 = fig.colorbar(hd1,cax=cax1)\n",
    "    cbar1.set_ticks(np.arange(vmin, vmax, (vmax-vmin)/6))\n",
    "    \n",
    "    hd2 = axs[2].imshow(np.log(img_denoised),origin='lower',vmin=vmin,vmax=vmax,cmap=reversed_cmap)\n",
    "#     hd2 = axs[2].imshow(np.log(img_denoised),origin='lower')\n",
    "    divider2 = make_axes_locatable(axs[2])\n",
    "    cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar2 = fig.colorbar(hd2,cax=cax2)\n",
    "    cbar2.set_ticks(np.arange(vmin, vmax, (vmax-vmin)/6))\n",
    "    \n",
    "    axs[0].set_title(r'direct: $\\ln (\\mathbf{d})$',fontsize=20)\n",
    "    axs[1].set_title(r'transmission: $\\ln (\\mathbf{d} + \\mathbf{s})$',fontsize=20)\n",
    "    axs[2].set_title(r'denoised transmission:  $-\\xi\\cdot\\mathcal{A}[\\mathbf{\\rho}_{\\mathrm{denoised}}]$',fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "# dir_fig = '/home/leo/hydro/figures/t40_radiograph_cmp_type1.eps'\n",
    "dir_fig = '/home/leo/hydro/figures/t40_radiograph_cmp_type2.eps'\n",
    "plt.savefig(dir_fig,format='eps',dpi=100,transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4(a) and 4(b): density frame examples --- ground truth\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "figsize = (25,10)\n",
    "fontsize = 16\n",
    "\n",
    "complete_on = False\n",
    "cbar_shrink=.9\n",
    "\n",
    "vmin = 0\n",
    "vmax = .42\n",
    "time_pts = [37 , 37.6, 38.1, 38.7, 39.3, 39.9, 40.4, 41]\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, figsize=figsize)\n",
    "for t in range(dep):\n",
    "    if time_pts is not None:\n",
    "        axs[t//ncols][t%ncols].set_title(f'$t = {time_pts[t]}$')\n",
    "    else:\n",
    "        axs[t//ncols][t%ncols].set_title('t = ' + str(t))\n",
    "    if complete_on:\n",
    "        hd = axs[t//ncols][t%ncols].imshow(complete(dyn[0,0,t,:,:]),vmin=vmin, vmax=vmax,origin='lower')\n",
    "    else:\n",
    "        hd = axs[t//ncols][t%ncols].imshow(dyn[0,0,t,:,:],vmin=vmin, vmax=vmax,origin='lower')\n",
    "#         divider = make_axes_locatable(axs[t//4][t%4])\n",
    "#         cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "#         fig.colorbar(hd,cax=cax)\n",
    "cbar = fig.colorbar(hd, ax=axs.ravel().tolist(), shrink=cbar_shrink)\n",
    "cbar.set_ticks(np.arange(vmin, vmax, (vmax-vmin)/10))\n",
    "plt.rcParams.update({'font.size': fontsize})\n",
    "plt.show()\n",
    "# dir_fig = '/home/leo/hydro/figures/gt_type1.eps'\n",
    "dir_fig = '/home/leo/hydro/figures/gt_type2.eps'\n",
    "plt.savefig(dir_fig,format='eps',dpi=100,transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8331f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Figure 5 and Figure 10: plot and save line profile\n",
    "line_index = 0\n",
    "plt_range =  320\n",
    "\n",
    "plt_type = 1\n",
    "\n",
    "nrows=2; ncols=4\n",
    "figsize=(18,9); fontsize=13\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, figsize=figsize)\n",
    "time_pts = [37 , 37.6, 38.1, 38.7, 39.3, 39.9, 40.4, 41]\n",
    "for t in range(dep): \n",
    "    plt.rcParams.update({'font.size': fontsize})\n",
    "    if plt_type == 1: # horizontal line profile\n",
    "        axs[t//ncols][t%ncols].plot(dyn[0,0,t,:plt_range,line_index], 'r', label='ground truth')\n",
    "        axs[t//ncols][t%ncols].plot(noisy_dyn[0,0,t,:plt_range,line_index], 'k', label='noisy data')\n",
    "#         axs[t//ncols][t%ncols].plot(denoised_dyn[0,0,t,:plt_range,line_index], 'g--', linewidth=2, label='denoised data')\n",
    "        axs[t//ncols][t%ncols].plot(further_denoised_dyn[0,0,t,:plt_range,line_index], '--', color='#00FF00',linewidth=3 ,label='denoised data')\n",
    "    elif plt_type == 2: # vertical line profile\n",
    "        axs[t//ncols][t%ncols].plot(dyn[0,0,t,line_index,:plt_range], 'r', label='ground truth')\n",
    "        axs[t//ncols][t%ncols].plot(noisy_dyn[0,0,t,line_index,:plt_range], 'k', label='noisy data')\n",
    "        axs[t//ncols][t%ncols].plot(denoised_dyn[0,0,t,line_index,:plt_range], 'g--', linewidth=2, label='denoised data')\n",
    "#         axs[t//ncols][t%ncols].plot(further_denoised_dyn[0,0,t,line_index,:plt_range], '--', color='#00FF00',linewidth=3 ,label='denoised data')\n",
    "    elif plt_type == 3: # diagonal line profile\n",
    "        gt = [dyn[0,0,t,i,i] for i in range(plt_range)]\n",
    "        noisy_sg = [noisy_dyn[0,0,t,i,i] for i in range(plt_range)]\n",
    "        denoised_sg = [further_denoised_dyn[0,0,t,i,i] for i in range(plt_range)]\n",
    "        axs[t//ncols][t%ncols].plot(gt, 'r', label='ground truth')\n",
    "        axs[t//ncols][t%ncols].plot(noisy_sg, 'k', label='noisy data')\n",
    "        axs[t//ncols][t%ncols].plot(denoised_sg, 'g--', linewidth=2, label='denoised data')\n",
    "    axs[t//ncols][t%ncols].set_title(f'$t = {time_pts[t]}$')\n",
    "#     axs[t//ncols][t%ncols].legend(loc='best')\n",
    "    \n",
    "\n",
    "handles, labels =  axs[1][2].get_legend_handles_labels()\n",
    "fig.legend(handles, labels=labels,loc=\"lower center\",ncol=3,fontsize='large',bbox_to_anchor=[.5, 0])\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "# dir_fig = '/home/leo/hydro/figures/line_profiles_type1_abelgaussian_scaling1.eps'\n",
    "# dir_fig = '/home/leo/hydro/figures/line_profiles_type2_abelgaussian_scaling1.eps'\n",
    "# dir_fig = '/home/leo/hydro/figures/line_profiles_type1_abelgaussiandouble_scaling1.eps'\n",
    "dir_fig = '/home/leo/hydro/figures/line_profiles_type2_abelgaussiandouble_scaling1.eps'\n",
    "plt.savefig(dir_fig,format='eps',dpi=600,transparent=True,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/mnt/DataB/hydro_simulations/newcase1/'\n",
    "ncfiles = list([])\n",
    "for file in os.listdir(datapath):\n",
    "    if file.endswith(\".dat\"):\n",
    "        ncfiles.append(file)\n",
    "print('Total amount of files:', len(ncfiles))\n",
    "\n",
    "data = np.loadtxt(datapath+ncfiles[0],skiprows=1)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot line profile\n",
    "line_index = 0\n",
    "plt_range =  320\n",
    "\n",
    "plt_type = 1\n",
    "\n",
    "for time_index in range(dep): \n",
    "    plt.figure(figsize=(5,5))\n",
    "    if plt_type == 1: # horizontal line profile\n",
    "        plt.plot(dyn[0,0,time_index,:plt_range,line_index], 'r', label='ground truth')\n",
    "        plt.plot(noisy_dyn[0,0,time_index,:plt_range,line_index], 'k', label='noisy data')\n",
    "#         plt.plot(denoised_dyn[0,0,time_index,:plt_range,line_index], 'g--', linewidth=2, label='denoised data')\n",
    "        plt.plot(further_denoised_dyn[0,0,time_index,:plt_range,line_index], '--', color='#00FF00',linewidth=3 ,label='post-processed data')\n",
    "    elif plt_type == 2: # vertical line profile\n",
    "        plt.plot(dyn[0,0,time_index,line_index,:plt_range], 'r',          label='ground truth')\n",
    "        plt.plot(noisy_dyn[0,0,time_index,line_index,:plt_range], 'k',    label='noisy data')\n",
    "#         plt.plot(denoised_dyn[0,0,time_index,line_index,:plt_range], 'g--', linewidth=2, label='denoised data')\n",
    "        plt.plot(further_denoised_dyn[0,0,time_index,line_index,:plt_range], label='post-processed data')\n",
    "    elif plt_type == 3: # diagonal line profile\n",
    "        gt = [dyn[0,0,time_index,i,i] for i in range(plt_range)]\n",
    "        noisy_sg = [noisy_dyn[0,0,time_index,i,i] for i in range(plt_range)]\n",
    "        denoised_sg = [further_denoised_dyn[0,0,time_index,i,i] for i in range(plt_range)]\n",
    "        plt.plot(gt, 'r', label='ground truth')\n",
    "        plt.plot(noisy_sg, 'k', label='noisy data')\n",
    "        plt.plot(denoised_sg, 'g--', linewidth=2, label='denoised data')\n",
    "    plt.title(f'time = {time_pts[time_index]}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3da43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple animation\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(41):\n",
    "    figsize=(10,10)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(dyn[0,0,i,:,:],origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.clim(0, .4)\n",
    "    plt.title('Frame %d' % (i+1))\n",
    "#     plt.title('Frame %d' % (i+1+dep*subgroup))\n",
    "#     plt.savefig(f'/home/huangz78/checkpoints/frame_{i}.jpg',bbox_inches='tight', transparent=True,\n",
    "#                pad_inches=.2, dpi=300)\n",
    "    plt.show()\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ca90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot line profile\n",
    "line_index = 0\n",
    "plt_range =  320\n",
    "\n",
    "plt_type = 1\n",
    "\n",
    "for time_index in range(dep): \n",
    "    plt.figure(figsize=(5,5))\n",
    "    if plt_type == 1: # horizontal line profile\n",
    "        plt.plot(dyn[0,0,time_index,:plt_range,line_index], 'r', label='ground truth')\n",
    "        plt.plot(noisy_dyn[0,0,time_index,:plt_range,line_index], 'k', label='noisy data')\n",
    "#         plt.plot(denoised_dyn[0,0,time_index,:plt_range,line_index], 'g--', linewidth=2, label='denoised data')\n",
    "        plt.plot(further_denoised_dyn[0,0,time_index,:plt_range,line_index], '--', color='#00FF00',linewidth=3 ,label='post-processed data')\n",
    "    elif plt_type == 2: # vertical line profile\n",
    "        plt.plot(dyn[0,0,time_index,line_index,:plt_range], 'r',          label='ground truth')\n",
    "        plt.plot(noisy_dyn[0,0,time_index,line_index,:plt_range], 'k',    label='noisy data')\n",
    "#         plt.plot(denoised_dyn[0,0,time_index,line_index,:plt_range], 'g--', linewidth=2, label='denoised data')\n",
    "        plt.plot(further_denoised_dyn[0,0,time_index,line_index,:plt_range], label='post-processed data')\n",
    "    elif plt_type == 3: # diagonal line profile\n",
    "        gt = [dyn[0,0,time_index,i,i] for i in range(plt_range)]\n",
    "        noisy_sg = [noisy_dyn[0,0,time_index,i,i] for i in range(plt_range)]\n",
    "        denoised_sg = [further_denoised_dyn[0,0,time_index,i,i] for i in range(plt_range)]\n",
    "        plt.plot(gt, 'r', label='ground truth')\n",
    "        plt.plot(noisy_sg, 'k', label='noisy data')\n",
    "        plt.plot(denoised_sg, 'g--', linewidth=2, label='denoised data')\n",
    "    plt.title(f'time = {time_pts[time_index]}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a365ac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dnet = Discriminator(ndf=4,sigmoid_on=True,imgsize=(8,320,320))\n",
    "dpath = '/mnt/DataA/checkpoints/leo/hydro/netD_wg_Abel-linear_epoch_6.pt'\n",
    "checkpoint = torch.load(dpath)\n",
    "dnet.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "\n",
    "dnet_params_num = dnet.n_params\n",
    "print('total amount of parameters in dnet: ', dnet_params_num )# dnet.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnet_params_num/dnet_params_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ef24d",
   "metadata": {},
   "source": [
    "## save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016b42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vmax_val = .5\n",
    "dir_fig = '/home/leo/hydro/figures/'\n",
    "illustrate(dyn, vmin=0, vmax=vmax_val,title_on=False,time_pts=time_pts,\\\n",
    "           save_path=dir_fig+'gt_type2.eps',dpi=150,nrows=4,ncols=2,figsize=(9,18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2def23d",
   "metadata": {},
   "source": [
    "## make figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fb17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_rec1 = '/home/leo/hydro/hist_Abel-gaussian_1.npz'\n",
    "dir_rec2 = '/home/leo/hydro/hist_Abel-gaussian_1_supwgt0.97_post_True.npz'\n",
    "dir_rec3 = '/home/leo/hydro/hist_Abel-gaussian_1_supwgt1.npz'\n",
    "dir_rec4 = '/home/leo/hydro/hist_Abel-gaussian_1_supwgt1_post_True.npz'\n",
    "\n",
    "dir_rec5 = '/home/leo/hydro/hist_Abel-gaussian-double_1.npz'\n",
    "dir_base = '/home/leo/hydro/hist_Abel-gaussian_1_baseline.npz'\n",
    "\n",
    "dir_rec6 = '/home/leo/hydro/hist_Abel-gaussian_2_supwgt0.97_post_False.npz'\n",
    "dir_rec7 = '/home/leo/hydro/hist_Abel-gaussian_2_supwgt1_post_False.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = np.load(dir_rec1)\n",
    "massdiff_gauss_1, nrmse_gauss_1, nl1err_gauss_1 = rec1['massdiff'], rec1['nrmse'], rec1['nl1err']\n",
    "\n",
    "rec2 = np.load(dir_rec2)\n",
    "massdiff_gauss_1p, nrmse_gauss_1p, nl1err_gauss_1p = rec2['massdiff'], rec2['nrmse'], rec2['nl1err']\n",
    "\n",
    "rec3 = np.load(dir_rec3)\n",
    "massdiff_gauss_1s, nrmse_gauss_1s, nl1err_gauss_1s = rec3['massdiff'], rec3['nrmse'], rec3['nl1err']\n",
    "\n",
    "rec4 = np.load(dir_rec4)\n",
    "massdiff_gauss_1sp, nrmse_gauss_1sp, nl1err_gauss_1sp = rec4['massdiff'], rec4['nrmse'], rec4['nl1err']\n",
    "\n",
    "rec5 = np.load(dir_rec5)\n",
    "massdiff_gauss_1d, nrmse_gauss_1d, nl1err_gauss_1d = rec5['massdiff'], rec5['nrmse'], rec5['nl1err']\n",
    "\n",
    "recbase = np.load(dir_base)\n",
    "massdiff_gauss_base, nrmse_gauss_base, nl1err_gauss_base = recbase['massdiff'], recbase['nrmse'], recbase['nl1err']\n",
    "\n",
    "rec6 = np.load(dir_rec6)\n",
    "massdiff_gauss_2, nrmse_gauss_2, nl1err_gauss_2= rec6['massdiff'], rec6['nrmse'], rec6['nl1err']\n",
    "\n",
    "rec7 = np.load(dir_rec7)\n",
    "massdiff_gauss_2_sup, nrmse_gauss_2_sup, nl1err_gauss_2_sup = rec7['massdiff'], rec7['nrmse'], rec7['nl1err']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(nrmse_gauss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(nrmse_gauss_2_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49dc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9: Generalization\n",
    "\n",
    "figsize=(55,10)\n",
    "label_fontsize = 45\n",
    "tick_fontsize=40\n",
    "nrows=1\n",
    "ncols=3\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, figsize=figsize)\n",
    "labels = ['WGAN-sup', 'supervised']\n",
    "scaling = 2\n",
    "data = [nrmse_gauss_2, nrmse_gauss_2_sup]\n",
    "axs[0].boxplot(data,notch=True)\n",
    "axs[0].set_xticklabels(labels,fontsize=label_fontsize)\n",
    "axs[0].set_ylabel(r\"Relative $\\ell_2$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[0].tick_params(axis='x', which='major', labelsize=tick_fontsize,rotation=0)\n",
    "axs[0].tick_params(axis='y', which='major', labelsize=tick_fontsize*.9,rotation=0)\n",
    "\n",
    "data = [nl1err_gauss_2, nl1err_gauss_2_sup]\n",
    "axs[1].boxplot(data,notch=True)\n",
    "axs[1].set_xticklabels(labels,fontsize=label_fontsize)\n",
    "axs[1].set_ylabel(r\"Relative $\\ell_1$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[1].tick_params(axis='x', which='major', labelsize=tick_fontsize,rotation=0)\n",
    "axs[1].tick_params(axis='y', which='major', labelsize=tick_fontsize*.9,rotation=0)\n",
    "\n",
    "data = [massdiff_gauss_2,massdiff_gauss_2_sup]\n",
    "axs[2].boxplot(data,notch=True)\n",
    "axs[2].set_xticklabels(labels,fontsize=label_fontsize)\n",
    "axs[2].set_ylabel(r\"Relative $\\ell_2$ error in Mass\",fontsize=label_fontsize)\n",
    "axs[2].tick_params(axis='x', which='major', labelsize=tick_fontsize,rotation=0)\n",
    "axs[2].tick_params(axis='y', which='major', labelsize=tick_fontsize*.9,rotation=0)\n",
    "plt.show()\n",
    "\n",
    "dir_fig = f'/home/leo/hydro/figures/error_gaussian_{scaling}.eps'\n",
    "# plt.savefig(dir_fig,format='eps',dpi=600,transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8: Accuracy comparison\n",
    "\n",
    "figsize=(60,10)\n",
    "label_fontsize = 45\n",
    "tick_fontsize = 45\n",
    "nrows=1; \n",
    "ncols=3\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, figsize=figsize)\n",
    "\n",
    "data = [nrmse_gauss_base,nrmse_gauss_1,nrmse_gauss_1s,nrmse_gauss_1p,nrmse_gauss_1sp]\n",
    "labels = ['baseline', 'WGAN-sup','supervised','WGAN-sup + p.p.', 'supervised + p.p']\n",
    "\n",
    "axs[0].boxplot(data,notch=True)\n",
    "axs[0].set_xticklabels(labels,fontsize=label_fontsize)\n",
    "axs[0].set_ylabel(r\"Relative $\\ell_2$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[0].tick_params(axis='x', which='major', labelsize=tick_fontsize,rotation=50)\n",
    "axs[0].tick_params(axis='y', which='major', labelsize=tick_fontsize,rotation=0)\n",
    "\n",
    "data = [nl1err_gauss_base,nl1err_gauss_1,nl1err_gauss_1s,nl1err_gauss_1p,nl1err_gauss_1sp]\n",
    "axs[1].boxplot(data,notch=True)\n",
    "axs[1].set_xticklabels(labels,fontsize=label_fontsize)\n",
    "axs[1].set_ylabel(r\"Relative $\\ell_1$ error in $\\mathbf{\\rho}$\",fontsize=label_fontsize)\n",
    "axs[1].tick_params(axis='x', which='major', labelsize=tick_fontsize,rotation=50)\n",
    "axs[1].tick_params(axis='y', which='major', labelsize=tick_fontsize,rotation=0)\n",
    "\n",
    "data = [massdiff_gauss_base,massdiff_gauss_1,massdiff_gauss_1s,massdiff_gauss_1p,massdiff_gauss_1sp]\n",
    "axs[2].boxplot(data,notch=True)\n",
    "axs[2].set_xticklabels(labels,fontsize=label_fontsize)\n",
    "axs[2].set_ylabel(r\"Relative $\\ell_2$ error in Mass\",fontsize=label_fontsize)\n",
    "axs[2].tick_params(axis='x', which='major', labelsize=tick_fontsize,rotation=50)\n",
    "axs[2].tick_params(axis='y', which='major', labelsize=tick_fontsize,rotation=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "dir_fig = '/home/leo/hydro/figures/error_gaussian.eps'\n",
    "# plt.savefig(dir_fig,format='eps',dpi=600,transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23fabe4",
   "metadata": {},
   "source": [
    "## Does netD tells noisy dynamics from clean dynamics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load slices\n",
    "ngpu = 1\n",
    "traintotal = 1000\n",
    "labels_gt = list([])\n",
    "labels_pred = list([])\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
    "use_cuda = True if (torch.cuda.is_available() and ngpu > 0) else False\n",
    "datapath = '/mnt/DataB/hydro_simulations/data/'\n",
    "ncfiles = list([])\n",
    "for file in os.listdir(datapath):\n",
    "    if file.endswith(\".nc\"):\n",
    "        ncfiles.append(file)\n",
    "print('Total amount of available files:', len(ncfiles))\n",
    "print('Train file amount: {}'.format(traintotal))\n",
    "\n",
    "filestart  = 8000\n",
    "trainfiles = ncfiles[filestart:filestart+traintotal+800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e33bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dnet.eval()\n",
    "device = torch.device('cuda:0')\n",
    "dnet.to(device)\n",
    "b_size = 5;  dep = 8; img_size = 320; resize_option = False; noise_mode = 'real'; normalize_factor = 50\n",
    "with torch.no_grad():\n",
    "    fileind = 0          \n",
    "    while fileind < traintotal:\n",
    "        # set the model back to training mode\n",
    "        dyn, noise = load_data_batch(fileind, trainfiles, \\\n",
    "                                     b_size=b_size, dep=dep, img_size=img_size,\\\n",
    "                                     resize_option=resize_option,\\\n",
    "                                     noise_mode=noise_mode, normalize_factor=normalize_factor)\n",
    "        noise    = noise.to(device)\n",
    "        real_cpu = dyn.to(device)\n",
    "\n",
    "        label_real = torch.full((b_size,), 1., dtype=torch.float, device=device)\n",
    "        labels_gt.extend(list(label_real.flatten().cpu().numpy()))\n",
    "        label_pred = torch.round(dnet(real_cpu).detach())\n",
    "        labels_pred.extend(list(label_pred.flatten().cpu().numpy()))\n",
    "        \n",
    "        label_fake = torch.full((b_size,), 0., dtype=torch.float, device=device)\n",
    "        labels_gt.extend(list(label_fake.flatten().cpu().numpy()))\n",
    "        label_pred = torch.round(dnet(real_cpu+noise).detach())\n",
    "        labels_pred.extend(list(label_pred.flatten().cpu().numpy()))\n",
    "        \n",
    "        print(f'current prediction accuracy = {1 - (torch.tensor(labels_pred)- torch.tensor(labels_gt)).abs().sum().item() / len(labels_gt)}')\n",
    "        fileind += b_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels_gt, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019957d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4eeef0b",
   "metadata": {},
   "source": [
    "# Is denoising in the Fourier domain a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24734c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = torch.tensor(np.linspace(0,2*np.pi,256))\n",
    "y  = torch.sin(x)\n",
    "z  = torch.ones_like(x) * 0.5\n",
    "yy = y + z\n",
    "\n",
    "f  = F.fft(y)\n",
    "ff = F.fft(yy)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(torch.abs(f[0:50]),label='f')\n",
    "# plt.plot(torch.abs(ff),label='ff')\n",
    "plt.legend(loc='best')\n",
    "# plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "# plt.plot(torch.abs(f),label='f')\n",
    "plt.plot(torch.abs(ff[0:50]),label='ff')\n",
    "plt.legend(loc='best')\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19966836",
   "metadata": {},
   "source": [
    "# check conservation of mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/mnt/shared_b/data/hydro_simulations/data/'\n",
    "ncfiles = list([])\n",
    "for file in os.listdir(datapath):\n",
    "    if file.endswith(\".nc\"):\n",
    "        ncfiles.append(file)\n",
    "print('Total amount of files:', len(ncfiles))\n",
    "img_size = 320\n",
    "dep = 41\n",
    "\n",
    "batchsize = 5\n",
    "fileexp_inds = [7736+i for i in range(batchsize)]\n",
    "\n",
    "dyn   = torch.zeros((batchsize,1,dep,img_size,img_size))    # load one sample, show it\n",
    "noise = torch.zeros((batchsize,1,dep,img_size,img_size))    # make a noise sample, add it to the ground truth, show it\n",
    "\n",
    "for fileexp_ind in range(len(fileexp_inds)):\n",
    "    filename = ncfiles[fileexp_inds[fileexp_ind]]\n",
    "    sim = xr.open_dataarray(datapath+filename)\n",
    "    # val.append(np.max(np.array(sim)[:dep,:,:].flatten()))\n",
    "    sim.close()\n",
    "    for t in range(dep):\n",
    "        dyn[fileexp_ind,0,t,:,:] = torch.tensor( sim.isel(t=t)[:img_size,:img_size].values )\n",
    "\n",
    "# dyn   = np.zeros((1,1,dep,256,256))    # load one sample, show it\n",
    "# noise = np.zeros((1,1,dep,256,256))    # make a noise sample, add it to the ground truth, show it\n",
    "# for t in range(dep):\n",
    "#     dyn[0,0,t,:,:] = resize(sim.isel(t=t)[:img_size,:img_size].values,(256,256),anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551d543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check conservation of mass\n",
    "\n",
    "mass = np.zeros(dep)\n",
    "for ind in range(dep):\n",
    "    img = dyn[0,0,ind,:,:]\n",
    "    mass[ind] = integration_over_sphere(img)\n",
    "plt.scatter(range(dep),mass)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dyn[0,0,0,:,:]\n",
    "plt.imshow(img,origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mass(imgs,Rrho=1,Rz=1):\n",
    "    '''\n",
    "    computing through cylindrical coordinate\n",
    "    '''\n",
    "    drho = Rrho / imgs.shape[3]\n",
    "    dz   = Rz   / imgs.shape[4]\n",
    "    metrics = torch.linspace(0,Rrho,imgs.shape[4]).repeat(imgs.shape[3],1)\n",
    "    integrand = imgs * metrics\n",
    "    mass = 2*np.pi * torch.sum(integrand,dim=(3,4)) * drho * dz \n",
    "    return torch.squeeze(mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34416472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_mass(dyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dddfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = np.zeros(dep)\n",
    "for ind in range(dep):\n",
    "    img = dyn[0,0,ind,:,:]\n",
    "    mass[ind] = compute_mass(img)\n",
    "plt.scatter(range(dep),mass)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707268d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mass(rho, R, z):\n",
    "    dR = R[1] - R[0]\n",
    "    dz = z[1] - z[0]\n",
    "    m = sum(2*np.pi*R[:]*rho[:])*dR*dz\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_r, grid_theta = np.mgrid[0:1:301j, np.pi/2:np.pi:301j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8796dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grid_r.T,origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('r grid')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(grid_theta.T,origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('theta grid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adec832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration_over_sphere(img,img_size=320,grid_len=300,method='cubic',R=1,Rx=1,Ry=1):\n",
    "    \n",
    "    grid_r, grid_theta = np.mgrid[0:R:301j, np.pi/2:np.pi:301j]\n",
    "    dr = 1/grid_len\n",
    "    dtheta = np.pi/(2*grid_len)\n",
    "    Cartesian_grid = [[i/img_size*Rx,j/img_size*Ry] for i in range(img_size) for j in range(img_size)]\n",
    "    radius = lambda x,y: np.sqrt(x**2 + y**2)\n",
    "    theta  = lambda x,y: np.arctan(x/y) + np.pi/2\n",
    "    \n",
    "    Spherical_grid = []\n",
    "    vals = []\n",
    "    for point in Cartesian_grid:\n",
    "        if point[0]==0:\n",
    "            Spherical_grid.append([point[1],np.pi/2])\n",
    "        elif (point[1]==0) and (point[0]!=0):\n",
    "            Spherical_grid.append([point[0],np.pi])\n",
    "        else:\n",
    "            Spherical_grid.append([radius(point[0],point[1]),theta(point[0],point[1])])\n",
    "        vals.append(img[int(point[0]*img_size/Rx),int(point[1]*img_size/Ry)])\n",
    "        \n",
    "    Spherical_grid = np.array(Spherical_grid)\n",
    "#     Cartesian_grid = np.array(Cartesian_grid)\n",
    "    vals = np.array(vals)\n",
    "\n",
    "    den_interp = griddata(Spherical_grid, vals, (grid_r, grid_theta), method=method).T\n",
    "    metric = (grid_r.T)**2 * np.sin(grid_theta.T)\n",
    "    \n",
    "    mass = np.sum(metric * np.nan_to_num(den_interp)) * dr * dtheta\n",
    "    \n",
    "    return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Spherical_grid[:,0],Spherical_grid[:,1],c=vals)\n",
    "plt.xlabel('radius')\n",
    "plt.ylabel('theta')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(den_interp.T, extent=(0,1,np.pi/2,np.pi), origin='lower')\n",
    "plt.title('Cubic interpolation')\n",
    "plt.gcf().set_size_inches(6, 6)\n",
    "plt.colorbar()\n",
    "plt.xlabel('radius')\n",
    "plt.ylabel('theta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Spherical_grid[:,0],Spherical_grid[:,1],vals)\n",
    "ax.set_xlabel('r')\n",
    "ax.set_ylabel('theta')\n",
    "ax.set_zlabel('val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ad17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn = np.loadtxt('/home/huangz78/hydro/leo1_trada.txt')\n",
    "heg = 860\n",
    "wid = 880\n",
    "dx = 2.558140 * 1e-2 \n",
    "dy = 2.500000 * 1e-2\n",
    "dyn = np.reshape(dyn,(heg,wid))\n",
    "Rx = dx * 320\n",
    "Ry = dy * 320\n",
    "R  = min(Rx,Ry)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(dyn)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgslice = dyn[heg//2:heg//2+320,wid//2:wid//2+320]\n",
    "plt.imshow(imgslice)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a136c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_over_sphere(imgslice,R=R,Rx=Rx,Ry=Ry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a90f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heg = 860\n",
    "wid = 880\n",
    "dx = 2.558140 * 1e-2 \n",
    "dy = 2.500000 * 1e-2\n",
    "\n",
    "weights = np.array([[i**2+j**2 for j in (np.arange(0,wid)-wid//2)*dy] for i in (np.arange(0,heg)-heg//2)*dx])\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(weights)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "summation = np.sum(np.multiply(weights,dyn))*(dx*dy)*4/3*np.pi\n",
    "print(summation)\n",
    "\n",
    "# summation = np.zeros((dep))\n",
    "# for t in range(dep):\n",
    "#     summation[t] = np.sum(np.multiply(weights,dyn[0,0,t,:,:]))\n",
    "# plt.figure()\n",
    "# plt.scatter(range(dep),summation)\n",
    "# plt.xlabel('frame number')\n",
    "# plt.ylabel('weighted summation of pixels')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771453d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = np.array([[i**2+j**2 for i in np.arange(0,img_size)/img_size] for j in np.arange(0,img_size)/img_size])\n",
    "plt.figure()\n",
    "plt.imshow(weights)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "summation = np.zeros((dep))\n",
    "for t in range(dep):\n",
    "    summation[t] = np.sum(np.multiply(weights,dyn[0,0,t,:,:]))\n",
    "plt.figure()\n",
    "plt.scatter(range(dep),summation)\n",
    "plt.xlabel('frame number')\n",
    "plt.ylabel('weighted summation of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da761c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a9c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e61a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import imageio\n",
    "def create_gif(filenames, duration):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(imageio.imread(filename))\n",
    "    output_file = '/home/huangz78/checkpoints/Gif-%s.gif' % datetime.datetime.now().strftime('%Y-%M-%d-%H-%M-%S')\n",
    "    imageio.mimsave(output_file, images, duration=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59dd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=[f'/home/huangz78/checkpoints/frame_{i}.jpg' for i in range(41)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3feb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gif(filenames, .4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
